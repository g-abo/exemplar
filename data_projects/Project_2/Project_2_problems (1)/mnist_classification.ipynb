{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification\n",
    "In this exercise we will explore the performance of several classification techniques on classifying handwritten digits. The canonical dataset used is the MNIST dataset (https://en.wikipedia.org/wiki/MNIST_database). We will evaluate classifier performance through train/validation/test sets provided to you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will use TensorFlow (https://en.wikipedia.org/wiki/TensorFlow). <b>Ignore all warnings produced by the tensorflow library (or others that you are required to use in this project, e.g. scikit-learn).</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from utils import get_data_extract\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# For reproducibility \n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following line to retrieve the data and generate the training, validation, and test sets using the function <b>get_data_extract()</b> provided in <b>utils.py</b>. <br>\n",
    "<b>We want you to use the training, validation and test sets provided by this function, exclusively.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = get_data_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resolution of the images are all $28\\times 28$. The corresponding feature vector of an image is a $28^2=784$ length 1D array representing the row-major flattened version of the image (i.e. the rows are concatenated top-down). All values in the array are in the range $[0,1]$ representing the grayscale value at that point. Note to get the pixel value, you would have to multiply these values by $255$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What are the dimensions of $X_{train}, X_{val}, X_{test}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1 pt) Calculate dimensions here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Display the first two images of $X_{train}$. (You may find the <b>np.reshape()</b> and <b>plt.imshow()</b> methods useful.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1 pt) Display first two training images here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Print out the first two labels in $Y_{train}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1 pt) Print first two training labels here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the MNIST data extracts above to compare various classification algorithms. <b>ONLY use the data extracts provided above. </b> We are primarily interested in two metrics: \n",
    "1. the test set accuracy (0.0 being all incorrect and 1.0 being all correct)\n",
    "2. time it takes to train the model and produce classifications for the <b>test set</b> <br>\n",
    "\n",
    "$X_{train}, Y_{train}$ will be used for training while $X_{test}, Y_{test}$ will be used for evaluating performance. Some models will use $X_{val}, Y_{val}$ for parameter tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the exercise above for sklearn's <b>LogisticsRegression()</b> algorithm. You might find the following arguments helpful when initializing the model: <b>penalty='l1', C=1.0, tol=0.01, solver='liblinear'</b>. These parameters will help speed up the algorithm significantly. Produce the training time, test set prediction accuracy score and time taken to produce predictions. Format your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5 pts) Train Logistic Regression and report time\n",
    "# (5 pts) Test Logistic Regression and report accuracy, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>****** The folowing models take a long time to run so we suggest reading all parts of the exercise first before implementing code. *****</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression with Polynomial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add polynomial features to our logistic regression. For that purpose, extend $X_{train}$ with second moment information. Specifically, add the squared value of each pixel, and the empirical covariance matrix, where each column in each 28x28 image is treated as different measurements of the corresponding row (hint: you can look on each row of X_train as a 28x28 image and then use np.cov). Now, re-run the logistic regression procedure from the previous excercise. You might find the following arguments helpful when initializing the model: <b>penalty='l1', C=8.0, tol=0.01, solver='liblinear'</b>. These parameters will help speed up the algorithm significantly, and yield good performance. Produce the training time, test set prediction accuracy score and time taken to produce predictions. Format your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5 pts) Train Logistic Regression and report time\n",
    "# (5 pts) Test Logistic Regression and report accuracy, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q (4 pts): Does polynomial features improve the performance of the logistic regression model? Why does it necessary to use larger regularization coefficient in this case?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Repeat the classification exercises above for sklearn's kNN algorithm <b>KNeighborsClassifier()</b> using <b>k=1</b>. You might find the following arguments helpful when initializing the model: <b>algorithm='kd_tree', metric='minkowski', p=2</b>. These parameters will help speed up the algorithm significantly. However, the predictions will still be very slow. Produce the training time, test set prediction accuracy score and time taken to produce predictions. Format your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4 pts) Train kNN for k=1 and report time\n",
    "# (4 pts) Test kNN and report accuracy, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) For the kNN model trained above, what is the prediction accuracy on the <b>training set</b> $X_{train}, Y_{train}$ (this will take a while to compute)? Compare this to the the prediction accuracy on the training set for the <b>LogisticRegression model</b> (without polynomial features)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2 pts) Report kNN training accuracy\n",
    "# (2 pts) Report Logistic Regression training accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) (3 pts) Does anything surprise you about the Training set accuracies above? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) (3 pts) Can you think why there is such a large difference between the kNN algorithms's training and prediction times?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) For now, we have only tried <b>k=1</b> (choose the closet neighbor) according to the Euclidean distance metric <b>p=2</b>. Repeat the exercise above for the following combinations of parameters: <b> k $\\in$ {1, 3}, p $\\in$ {2, 3} </b>. Note that p=2 is the 2-norm (Euclidean distance) and p=3 is the 3-norm. Train each of the models on the training set and evaluate the accuracy on the <b>validation set</b> $X_{val}, Y_{val}$. <b>NOTE: this might take a while!</b> Report the validation set accuracy for each model. Format your answers.\n",
    "\n",
    "<b>Note:</b> We recommend following the code skeleton below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train kNN for all combinations of parameters above and report validation accuracy for each\n",
    "def runKNN(X_train,Y_train, X_val, Y_val, k, p):\n",
    "    # (6pts) your code below\n",
    "    \n",
    "    knn, val_score, train_time = None, None, None # TODO: compute\n",
    "    return (knn, val_score, train_time)\n",
    "\n",
    "best_score = 0.0\n",
    "best_k, best_p, best_knn = None, None, None\n",
    "best_train_time = np.inf\n",
    "\n",
    "for k in [1, 3]:\n",
    "    for p in [2, 3]:\n",
    "        (knn_model, val_score, train_time) = runKNN(X_train,Y_train, X_val, Y_val, k, p)\n",
    "        \n",
    "        # (each (k,p) combination 1 pt) your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) (1 pt) Based on the scores on the validation set, which parameters give the best model? Report the time taken to train the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Using the best model, evaluate performance on the <b>test set</b>. Produce the prediction accuracy score and time taken to produce predictions. Please format your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4 pts) Test best kNN and report accuracy, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now complete the tasks above using a simple Neural Network model.\n",
    "This portal comes with a tensorflow installation (see the imports at the very top of this file).\n",
    "Your task is the following:\n",
    "1. Adapt the tensorflow tutorial here (https://www.tensorflow.org/tutorials/quickstart/beginner) to train a simple Neural Network model\n",
    "2. You are required to use <b>ONLY</b> the $X_{train}, Y_{train}, X_{val}, Y_{val}, X_{test}, Y_{test}$ subsets provided earlier in this assignment. <b>DO NOT use any other subsets of the mnist dataset: you will have to adapt the tutorial to use the data provided in this assignment.</b>\n",
    "3. You will need to write a custom one-hot encoder for the labels\n",
    "   Hint: you might find the following libraries useful:\n",
    "\t\tfrom keras.utils import to_categorical\n",
    "4. Note that you will not need to use any validation in this part. Train using $X_{train}, Y_{train}$.\n",
    "5. Finally, produce the following: Time taken to train the model; Time taken to produce Test set predictions; Test set accuracy\n",
    "\n",
    "<b>Note:</b> We recommend following the code skeleton below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement simpleNN\n",
    "# Train simpleNN and report time\n",
    "# Test simpleNN and report accuracy, time\n",
    "\n",
    "def simple_nn(X, Y, X_val, Y_val, X_test, Y_test):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "     # (6 pts) your model here\n",
    "    ])\n",
    "    \n",
    "    # (1 pt) one-hot encode the labels\n",
    "    \n",
    "    # (2 pts) compile model\n",
    "    \n",
    "    process = model.fit(\n",
    "        # (4 pts) train model for 20 epochs and time it\n",
    "        # make sure to achieve 99% training accuracy\n",
    "    )\n",
    "    \n",
    "    # (4 pts) evaluate model and time it\n",
    "    \n",
    "    return process\n",
    "    \n",
    "simple_process = simple_nn(X_train, Y_train, X_val, Y_val, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2 pts) Plot the training and validation accuracy curves in the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: use simple_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now complete the tasks above using a more complicated model: Convolutional Neural Network.\n",
    "\n",
    "Your task is the following:\n",
    "1. Adapt the CNN tensorflow tutorial here (https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/) to train a Convolutional Neural Network model\n",
    "2. You are required to use <b>ONLY</b> the $X_{train}, Y_{train}, X_{val}, Y_{val}, X_{test}, Y_{test}$ subsets provided earlier in this assignment. <b>DO NOT use any other subsets of the mnist dataset: you will have to adapt the tutorial to use the data provided in this assignment.</b>\n",
    "3. Use the same one-hot encoder as the previous part\n",
    "4. Note that you will not need to use any validation in this part. Train using $X_{train}, Y_{train}$.\n",
    "5. Finally, produce the following:\n",
    "\tTime taken to train the model; Time taken to produce Test set predictions; Test set accuracy\n",
    "\n",
    "<b>Note:</b> We recommend following the code skeleton below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement CNN\n",
    "# Train CNN and report time\n",
    "# Test CNN and report accuracy, time\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def conv_nn(X, Y, X_test, Y_test):\n",
    "    # your code below\n",
    "    \n",
    "    # (1 pt) reshape dataset to have a single channel (see tutorial)\n",
    "\n",
    "    # (1 pt) one-hot encode the labels\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "     # (8 pts) your model here\n",
    "    ])\n",
    "    \n",
    "    # (2 pts) compile model\n",
    "    \n",
    "    process = model.fit(\n",
    "        # (4 pts) train model for 20 epochs and time it\n",
    "        # make sure to achieve 100% training accuracy\n",
    "    )\n",
    "    \n",
    "    # (4 pts) evaluate model and time it\n",
    "    \n",
    "    return process\n",
    "    \n",
    "conv_process = conv_nn(X_train, Y_train, X_val, Y_val, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2 pts) Plot the training and validation accuracy curves in the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: use conv_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3 pts) What do you observe in the plots showing training v.s. validation accuracies? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6 pts) Comment on the features of the various algorithms you have used in this assignment and the tradeoffs between computational efficiency and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
